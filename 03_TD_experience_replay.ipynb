{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 環境の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blindcliftwalk import BlindCliftwalk\n",
    "\n",
    "# ゴールまでの距離\n",
    "nb_step = 20\n",
    "#nb_step = 10\n",
    "\n",
    "# ゴールの数\n",
    "nb_goals = 3\n",
    "#nb_goals = 1\n",
    "\n",
    "env = BlindCliftwalk(nb_step, nb_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=50)\n",
    "env.set_ground_truth()\n",
    "env.ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10a921ac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICQ1/T9FxCB57HJjGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109912cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(env.ground_truth, 'rainbow', interpolation='nearest')\n",
    "#plt.savefig('ground_truth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# value functionをTD学習で学習する\n",
    "- [prioritized experience replay](https://arxiv.org/abs/1511.05952)を使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  state value更新回数\n",
    "#mc_step = 300000\n",
    "mc_step = 100000\n",
    "\n",
    "# 割引率\n",
    "gamma = 1. - 1. / float(nb_step)\n",
    "\n",
    "# 学習率\n",
    "learning_rate = 0.25\n",
    "\n",
    "# 考えうる状態の数はground_truthの大きさと同じ（もう少し小さいが、面倒なので同じとする）\n",
    "value_table = np.zeros_like(env.ground_truth, dtype=float)\n",
    "\n",
    "# ゴール到達後のstate valueの保存間隔\n",
    "#save_interval = 10000\n",
    "save_interval = 1000\n",
    "\n",
    "# Prioritized Experience Replayのハイパーパラメータ。α=0でランダムサンプリング\n",
    "alpha = 0.3\n",
    "#alpha = 0.\n",
    "beta = 1.\n",
    "\n",
    "# ε-greedyのハイパーパラメータ\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gumbel_sampling(prob):\n",
    "    rand = np.random.random(len(prob))\n",
    "    g = -np.log(-np.log(rand))\n",
    "    return np.argmax(g+np.log(prob))\n",
    "#    return np.argmax(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111b5c390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHpJapxBL0mN+38b0a6vAn4zgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109578c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob = [0.5, 0.3, 0.2]\n",
    "hist=[]\n",
    "for _ in range(1000):\n",
    "    hist.append(gumbel_sampling(prob))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.distplot(hist, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_prob(priorities, alpha):\n",
    "    foo = np.array(priorities)**alpha\n",
    "    return foo / np.array(foo).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 36733/100000 [00:10<00:18, 3393.54it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "stacked_value_table = []\n",
    "isSuccessed = False\n",
    "\n",
    "value_table = np.zeros_like(value_table) # state valueの初期化（念のためループ直前でも初期化する）\n",
    "experience = []\n",
    "priorities = []\n",
    "#eps = np.finfo(float).eps\n",
    "eps = 1e-5\n",
    "try:\n",
    "    count = 0\n",
    "    for i in tqdm(range(mc_step)):\n",
    "        # 状態の初期化\n",
    "        current_state  = np.zeros(2, dtype=int)\n",
    "\n",
    "        status = 0\n",
    "        while status >= 0:\n",
    "            # state valueが最大となる行動を取る（まだ遷移させない）。\n",
    "            if np.random.random(1) > epsilon:\n",
    "                action_candidates = [[0,1], [1,0]]\n",
    "                next_state_1, _, _ = env.do_action(current_state, action_candidates[0])\n",
    "                next_state_2, _, _ = env.do_action(current_state, action_candidates[1])\n",
    "                v1 = value_table[next_state_1[0], next_state_1[1]]\n",
    "                v2 = value_table[next_state_2[0], next_state_2[1]]\n",
    "                v_candidates = np.array([v1,v2])\n",
    "                action = action_candidates[v_candidates.argmax()]\n",
    "            else:\n",
    "                action = env.random_action()\n",
    "                \n",
    "            # 行動に対する報酬と遷移後の状態の計算\n",
    "            next_state, reward, status = env.do_action(current_state, action)\n",
    "            \n",
    "            if status==1:\n",
    "                isSuccessed = True\n",
    "\n",
    "            if status>=0:\n",
    "                if False:\n",
    "                    '''\n",
    "                    原著論文ではとりあえず最大priorityで遷移を経験に保存しているが、\n",
    "                    これだと最初にゴールに到達した経験も過去の経験と同じpriorityになってしまう。\n",
    "                    そこで、ここではTD誤差を計算してTD誤差から計算されるpriorityを保存する。\n",
    "                    一度でもこの経験が再生されればpriorityは更新される。\n",
    "                    '''\n",
    "                    V_1 = value_table[current_state[0], current_state[1]]\n",
    "                    V_2 = value_table[next_state[0], next_state[1]]\n",
    "                    replayed_td_error = reward + gamma * V_2 - V_1\n",
    "                    priority = abs(replayed_td_error) + eps\n",
    "                else:\n",
    "                    try:\n",
    "                        priority = np.array(priorities).max()\n",
    "                    except:\n",
    "                        priority = 1.\n",
    "                experience.append((current_state, action, next_state, reward))\n",
    "                priorities.append(priority)\n",
    "                \n",
    "                # 経験が100個以上溜まったら、priorityの低い経験から削除していく。\n",
    "                if len(priorities)>100:\n",
    "                    del_idx = np.array(priorities).argmin()\n",
    "                    experience.pop(del_idx)\n",
    "                    priorities.pop(del_idx)\n",
    "\n",
    "                # experience replay: 経験の中からpriorityの高い遷移をサンプリングして、state valueの更新に使う。\n",
    "                prob = trans_prob(priorities, alpha)\n",
    "                replay_idx = gumbel_sampling(prob)\n",
    "                s1, _, s2, r = experience[replay_idx]\n",
    "                V_1 = value_table[s1[0], s1[1]]\n",
    "                V_2 = value_table[s2[0], s2[1]]\n",
    "                replayed_td_error = r + gamma * V_2 - V_1\n",
    "#                weight = (1./prob[replay_idx]/float(len(priorities)))**beta\n",
    "                weight = 1.\n",
    "                value_table[s1[0], s1[1]] = V_1 + learning_rate * weight * replayed_td_error\n",
    "\n",
    "                #一度再生された経験のpriorityを更新する。\n",
    "                V_1 = value_table[s1[0], s1[1]]\n",
    "                V_2 = value_table[s2[0], s2[1]]\n",
    "                post_td_error = r + gamma * V_2 - V_1\n",
    "#                priorities[replay_idx] = abs(post_td_error) + eps\n",
    "                priorities[replay_idx] = abs(replayed_td_error) + eps\n",
    "        \n",
    "                # 状態の遷移（マス目の移動）\n",
    "                current_state = next_state\n",
    "                \n",
    "                if isSuccessed:\n",
    "#                if True:\n",
    "                    count += 1\n",
    "                    if count==save_interval:\n",
    "                        stacked_value_table.append(np.copy(value_table))\n",
    "                        count = 0\n",
    "                    \n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習過程の可視化\n",
    "- TD学習では一度ゴールまでたどり着くとその後常にstate valueが更新される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(value_table, interpolation='nearest')\n",
    "plt.clim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stacked_value_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if isSuccessed:\n",
    "    nb_show = 100\n",
    "    nb = 0\n",
    "    plt.figure(figsize=(10,10*int(len(stacked_value_table[:nb_show])+1)/5.))\n",
    "    for v in stacked_value_table[:nb_show]:\n",
    "        nb += 1\n",
    "        plt.subplot(int(len(stacked_value_table[:nb_show])+1),5,nb)\n",
    "        plt.imshow(v, interpolation='nearest')\n",
    "        plt.clim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(stacked_value_table[:200]):\n",
    "    plt.imshow(v, interpolation='nearest')\n",
    "    plt.clim(0,1)\n",
    "    plt.title('# of action '+str(i*save_interval).zfill(3))\n",
    "    plt.savefig('TD_PER_iter_'+str(i).zfill(4)+'.png')\n",
    "#    plt.savefig('TD_RandomER_iter_'+str(i).zfill(4)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
